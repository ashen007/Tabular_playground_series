{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import get_\n",
    "import numpy as np\n",
    "import RegressionModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "getter = get_.data_('../data/train.csv')\n",
    "data = getter.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "           cont1     cont2     cont3     cont4     cont5     cont6     cont7  \\\nid                                                                             \n1       0.670390  0.811300  0.643968  0.291791  0.284117  0.855953  0.890700   \n3       0.388053  0.621104  0.686102  0.501149  0.643790  0.449805  0.510824   \n4       0.834950  0.227436  0.301584  0.293408  0.606839  0.829175  0.506143   \n5       0.820708  0.160155  0.546887  0.726104  0.282444  0.785108  0.752758   \n8       0.935278  0.421235  0.303801  0.880214  0.665610  0.830131  0.487113   \n...          ...       ...       ...       ...       ...       ...       ...   \n499995  0.216974  0.735265  0.648648  0.255387  0.616353  0.345197  0.295718   \n499996  0.545799  0.165139  0.220966  0.190053  0.359362  0.386336  0.365767   \n499997  0.284401  0.841542  0.957585  0.340383  0.396279  0.330376  0.525687   \n499998  0.481900  0.622346  0.540032  0.823118  0.283066  0.434283  0.174342   \n499999  0.486632  0.230090  0.543587  0.263878  0.279118  0.636295  0.472391   \n\n           cont8     cont9    cont10    cont11    cont12    cont13    cont14  \\\nid                                                                             \n1       0.285542  0.558245  0.779418  0.921832  0.866772  0.878733  0.305411   \n3       0.580748  0.418335  0.432632  0.439872  0.434971  0.369957  0.369484   \n4       0.558771  0.587603  0.823312  0.567007  0.677708  0.882938  0.303047   \n5       0.823267  0.574466  0.580843  0.769594  0.818143  0.914281  0.279528   \n8       0.604157  0.874658  0.863427  0.983575  0.900464  0.935918  0.435772   \n...          ...       ...       ...       ...       ...       ...       ...   \n499995  0.304357  0.314351  0.860504  0.315397  0.247682  0.486542  0.288750   \n499996  0.344217  0.466446  0.454581  0.360251  0.360755  0.292535  0.619984   \n499997  0.260039  0.378174  0.526925  0.491735  0.516629  0.173521  0.714552   \n499998  0.710843  0.358690  0.648272  0.984647  1.001110  0.063956  0.377693   \n499999  0.339654  0.444787  0.636765  0.782196  0.559692  0.762954  0.215539   \n\n          target  \nid                \n1       7.243043  \n3       8.203331  \n4       7.776091  \n5       6.957716  \n8       7.951046  \n...          ...  \n499995  7.385215  \n499996  7.242617  \n499997  9.592487  \n499998  8.207951  \n499999  8.890285  \n\n[300000 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cont1</th>\n      <th>cont2</th>\n      <th>cont3</th>\n      <th>cont4</th>\n      <th>cont5</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n      <th>cont14</th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.670390</td>\n      <td>0.811300</td>\n      <td>0.643968</td>\n      <td>0.291791</td>\n      <td>0.284117</td>\n      <td>0.855953</td>\n      <td>0.890700</td>\n      <td>0.285542</td>\n      <td>0.558245</td>\n      <td>0.779418</td>\n      <td>0.921832</td>\n      <td>0.866772</td>\n      <td>0.878733</td>\n      <td>0.305411</td>\n      <td>7.243043</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.388053</td>\n      <td>0.621104</td>\n      <td>0.686102</td>\n      <td>0.501149</td>\n      <td>0.643790</td>\n      <td>0.449805</td>\n      <td>0.510824</td>\n      <td>0.580748</td>\n      <td>0.418335</td>\n      <td>0.432632</td>\n      <td>0.439872</td>\n      <td>0.434971</td>\n      <td>0.369957</td>\n      <td>0.369484</td>\n      <td>8.203331</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.834950</td>\n      <td>0.227436</td>\n      <td>0.301584</td>\n      <td>0.293408</td>\n      <td>0.606839</td>\n      <td>0.829175</td>\n      <td>0.506143</td>\n      <td>0.558771</td>\n      <td>0.587603</td>\n      <td>0.823312</td>\n      <td>0.567007</td>\n      <td>0.677708</td>\n      <td>0.882938</td>\n      <td>0.303047</td>\n      <td>7.776091</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.820708</td>\n      <td>0.160155</td>\n      <td>0.546887</td>\n      <td>0.726104</td>\n      <td>0.282444</td>\n      <td>0.785108</td>\n      <td>0.752758</td>\n      <td>0.823267</td>\n      <td>0.574466</td>\n      <td>0.580843</td>\n      <td>0.769594</td>\n      <td>0.818143</td>\n      <td>0.914281</td>\n      <td>0.279528</td>\n      <td>6.957716</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.935278</td>\n      <td>0.421235</td>\n      <td>0.303801</td>\n      <td>0.880214</td>\n      <td>0.665610</td>\n      <td>0.830131</td>\n      <td>0.487113</td>\n      <td>0.604157</td>\n      <td>0.874658</td>\n      <td>0.863427</td>\n      <td>0.983575</td>\n      <td>0.900464</td>\n      <td>0.935918</td>\n      <td>0.435772</td>\n      <td>7.951046</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>499995</th>\n      <td>0.216974</td>\n      <td>0.735265</td>\n      <td>0.648648</td>\n      <td>0.255387</td>\n      <td>0.616353</td>\n      <td>0.345197</td>\n      <td>0.295718</td>\n      <td>0.304357</td>\n      <td>0.314351</td>\n      <td>0.860504</td>\n      <td>0.315397</td>\n      <td>0.247682</td>\n      <td>0.486542</td>\n      <td>0.288750</td>\n      <td>7.385215</td>\n    </tr>\n    <tr>\n      <th>499996</th>\n      <td>0.545799</td>\n      <td>0.165139</td>\n      <td>0.220966</td>\n      <td>0.190053</td>\n      <td>0.359362</td>\n      <td>0.386336</td>\n      <td>0.365767</td>\n      <td>0.344217</td>\n      <td>0.466446</td>\n      <td>0.454581</td>\n      <td>0.360251</td>\n      <td>0.360755</td>\n      <td>0.292535</td>\n      <td>0.619984</td>\n      <td>7.242617</td>\n    </tr>\n    <tr>\n      <th>499997</th>\n      <td>0.284401</td>\n      <td>0.841542</td>\n      <td>0.957585</td>\n      <td>0.340383</td>\n      <td>0.396279</td>\n      <td>0.330376</td>\n      <td>0.525687</td>\n      <td>0.260039</td>\n      <td>0.378174</td>\n      <td>0.526925</td>\n      <td>0.491735</td>\n      <td>0.516629</td>\n      <td>0.173521</td>\n      <td>0.714552</td>\n      <td>9.592487</td>\n    </tr>\n    <tr>\n      <th>499998</th>\n      <td>0.481900</td>\n      <td>0.622346</td>\n      <td>0.540032</td>\n      <td>0.823118</td>\n      <td>0.283066</td>\n      <td>0.434283</td>\n      <td>0.174342</td>\n      <td>0.710843</td>\n      <td>0.358690</td>\n      <td>0.648272</td>\n      <td>0.984647</td>\n      <td>1.001110</td>\n      <td>0.063956</td>\n      <td>0.377693</td>\n      <td>8.207951</td>\n    </tr>\n    <tr>\n      <th>499999</th>\n      <td>0.486632</td>\n      <td>0.230090</td>\n      <td>0.543587</td>\n      <td>0.263878</td>\n      <td>0.279118</td>\n      <td>0.636295</td>\n      <td>0.472391</td>\n      <td>0.339654</td>\n      <td>0.444787</td>\n      <td>0.636765</td>\n      <td>0.782196</td>\n      <td>0.559692</td>\n      <td>0.762954</td>\n      <td>0.215539</td>\n      <td>8.890285</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dtl,outliers = getter.zScore(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'cont1': 0,\n 'cont2': 0,\n 'cont3': 0,\n 'cont4': 0,\n 'cont5': 0,\n 'cont6': 0,\n 'cont7': 1829,\n 'cont8': 0,\n 'cont9': 5489,\n 'cont10': 41,\n 'cont11': 0,\n 'cont12': 0,\n 'cont13': 0,\n 'cont14': 0,\n 'target': 87}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "292572"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0] - len(outliers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "getter.norm_data(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "           cont1     cont2     cont3     cont4     cont5     cont6     cont7  \\\nid                                                                             \n1       0.670390  0.811300  0.643968  0.291791  0.284117  0.855953  0.890700   \n3       0.388053  0.621104  0.686102  0.501149  0.643790  0.449805  0.510824   \n4       0.834950  0.227436  0.301584  0.293408  0.606839  0.829175  0.506143   \n5       0.820708  0.160155  0.546887  0.726104  0.282444  0.785108  0.752758   \n8       0.935278  0.421235  0.303801  0.880214  0.665610  0.830131  0.487113   \n...          ...       ...       ...       ...       ...       ...       ...   \n499995  0.216974  0.735265  0.648648  0.255387  0.616353  0.345197  0.295718   \n499996  0.545799  0.165139  0.220966  0.190053  0.359362  0.386336  0.365767   \n499997  0.284401  0.841542  0.957585  0.340383  0.396279  0.330376  0.525687   \n499998  0.481900  0.622346  0.540032  0.823118  0.283066  0.434283  0.174342   \n499999  0.486632  0.230090  0.543587  0.263878  0.279118  0.636295  0.472391   \n\n           cont8     cont9    cont10    cont11    cont12    cont13    cont14  \\\nid                                                                             \n1       0.285542  0.558245  0.779418  0.921832  0.866772  0.878733  0.305411   \n3       0.580748  0.418335  0.432632  0.439872  0.434971  0.369957  0.369484   \n4       0.558771  0.587603  0.823312  0.567007  0.677708  0.882938  0.303047   \n5       0.823267  0.574466  0.580843  0.769594  0.818143  0.914281  0.279528   \n8       0.604157  0.874658  0.863427  0.983575  0.900464  0.935918  0.435772   \n...          ...       ...       ...       ...       ...       ...       ...   \n499995  0.304357  0.314351  0.860504  0.315397  0.247682  0.486542  0.288750   \n499996  0.344217  0.466446  0.454581  0.360251  0.360755  0.292535  0.619984   \n499997  0.260039  0.378174  0.526925  0.491735  0.516629  0.173521  0.714552   \n499998  0.710843  0.358690  0.648272  0.984647  1.001110  0.063956  0.377693   \n499999  0.339654  0.444787  0.636765  0.782196  0.559692  0.762954  0.215539   \n\n          target  \nid                \n1       7.243043  \n3       8.203331  \n4       7.776091  \n5       6.957716  \n8       7.951046  \n...          ...  \n499995  7.385215  \n499996  7.242617  \n499997  9.592487  \n499998  8.207951  \n499999  8.890285  \n\n[292572 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cont1</th>\n      <th>cont2</th>\n      <th>cont3</th>\n      <th>cont4</th>\n      <th>cont5</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n      <th>cont14</th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.670390</td>\n      <td>0.811300</td>\n      <td>0.643968</td>\n      <td>0.291791</td>\n      <td>0.284117</td>\n      <td>0.855953</td>\n      <td>0.890700</td>\n      <td>0.285542</td>\n      <td>0.558245</td>\n      <td>0.779418</td>\n      <td>0.921832</td>\n      <td>0.866772</td>\n      <td>0.878733</td>\n      <td>0.305411</td>\n      <td>7.243043</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.388053</td>\n      <td>0.621104</td>\n      <td>0.686102</td>\n      <td>0.501149</td>\n      <td>0.643790</td>\n      <td>0.449805</td>\n      <td>0.510824</td>\n      <td>0.580748</td>\n      <td>0.418335</td>\n      <td>0.432632</td>\n      <td>0.439872</td>\n      <td>0.434971</td>\n      <td>0.369957</td>\n      <td>0.369484</td>\n      <td>8.203331</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.834950</td>\n      <td>0.227436</td>\n      <td>0.301584</td>\n      <td>0.293408</td>\n      <td>0.606839</td>\n      <td>0.829175</td>\n      <td>0.506143</td>\n      <td>0.558771</td>\n      <td>0.587603</td>\n      <td>0.823312</td>\n      <td>0.567007</td>\n      <td>0.677708</td>\n      <td>0.882938</td>\n      <td>0.303047</td>\n      <td>7.776091</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.820708</td>\n      <td>0.160155</td>\n      <td>0.546887</td>\n      <td>0.726104</td>\n      <td>0.282444</td>\n      <td>0.785108</td>\n      <td>0.752758</td>\n      <td>0.823267</td>\n      <td>0.574466</td>\n      <td>0.580843</td>\n      <td>0.769594</td>\n      <td>0.818143</td>\n      <td>0.914281</td>\n      <td>0.279528</td>\n      <td>6.957716</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.935278</td>\n      <td>0.421235</td>\n      <td>0.303801</td>\n      <td>0.880214</td>\n      <td>0.665610</td>\n      <td>0.830131</td>\n      <td>0.487113</td>\n      <td>0.604157</td>\n      <td>0.874658</td>\n      <td>0.863427</td>\n      <td>0.983575</td>\n      <td>0.900464</td>\n      <td>0.935918</td>\n      <td>0.435772</td>\n      <td>7.951046</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>499995</th>\n      <td>0.216974</td>\n      <td>0.735265</td>\n      <td>0.648648</td>\n      <td>0.255387</td>\n      <td>0.616353</td>\n      <td>0.345197</td>\n      <td>0.295718</td>\n      <td>0.304357</td>\n      <td>0.314351</td>\n      <td>0.860504</td>\n      <td>0.315397</td>\n      <td>0.247682</td>\n      <td>0.486542</td>\n      <td>0.288750</td>\n      <td>7.385215</td>\n    </tr>\n    <tr>\n      <th>499996</th>\n      <td>0.545799</td>\n      <td>0.165139</td>\n      <td>0.220966</td>\n      <td>0.190053</td>\n      <td>0.359362</td>\n      <td>0.386336</td>\n      <td>0.365767</td>\n      <td>0.344217</td>\n      <td>0.466446</td>\n      <td>0.454581</td>\n      <td>0.360251</td>\n      <td>0.360755</td>\n      <td>0.292535</td>\n      <td>0.619984</td>\n      <td>7.242617</td>\n    </tr>\n    <tr>\n      <th>499997</th>\n      <td>0.284401</td>\n      <td>0.841542</td>\n      <td>0.957585</td>\n      <td>0.340383</td>\n      <td>0.396279</td>\n      <td>0.330376</td>\n      <td>0.525687</td>\n      <td>0.260039</td>\n      <td>0.378174</td>\n      <td>0.526925</td>\n      <td>0.491735</td>\n      <td>0.516629</td>\n      <td>0.173521</td>\n      <td>0.714552</td>\n      <td>9.592487</td>\n    </tr>\n    <tr>\n      <th>499998</th>\n      <td>0.481900</td>\n      <td>0.622346</td>\n      <td>0.540032</td>\n      <td>0.823118</td>\n      <td>0.283066</td>\n      <td>0.434283</td>\n      <td>0.174342</td>\n      <td>0.710843</td>\n      <td>0.358690</td>\n      <td>0.648272</td>\n      <td>0.984647</td>\n      <td>1.001110</td>\n      <td>0.063956</td>\n      <td>0.377693</td>\n      <td>8.207951</td>\n    </tr>\n    <tr>\n      <th>499999</th>\n      <td>0.486632</td>\n      <td>0.230090</td>\n      <td>0.543587</td>\n      <td>0.263878</td>\n      <td>0.279118</td>\n      <td>0.636295</td>\n      <td>0.472391</td>\n      <td>0.339654</td>\n      <td>0.444787</td>\n      <td>0.636765</td>\n      <td>0.782196</td>\n      <td>0.559692</td>\n      <td>0.762954</td>\n      <td>0.215539</td>\n      <td>8.890285</td>\n    </tr>\n  </tbody>\n</table>\n<p>292572 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "target = data['target']\n",
    "train = data.drop('target',axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([ 1.56156562,  0.16027271,  4.36466956,  1.79130476,  1.58174348,\n        -0.26833368,  2.45775279,  0.89394609,  0.51824867, -0.07595058,\n        -0.74926121, -0.52326601,  1.76858365,  1.6255271 ]),\n array([517008.0123585]))"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c,i = np.linalg.lstsq(train,target,rcond=None)[:2]\n",
    "c,i"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "ols_model = RegressionModels.OLS()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-15-5cee7189e419>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mcoeff\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mintercept\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mols_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtarget\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mcoeff\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mintercept\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Machine Learning\\project library\\Tabular playground series\\models\\RegressionModels.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(x, y)\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[1;33m:\u001B[0m\u001B[1;32mreturn\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mcoefficients\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mintercept\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m         \"\"\"\n\u001B[1;32m---> 13\u001B[1;33m         \u001B[0mtheta\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mintercept\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinalg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstsq\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrcond\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtheta\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mintercept\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "coeff,intercept = ols_model.fit(train,target)\n",
    "coeff,intercept"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "gd_model = RegressionModels.GradientDecent()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 14 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-21-3d135aeca6dc>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mcost\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgd_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtarget\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m10001\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mcost\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Machine Learning\\project library\\Tabular playground series\\models\\RegressionModels.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(x, y, learning_rate, epochs)\u001B[0m\n\u001B[0;32m     47\u001B[0m         \u001B[0mtheta\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m         \u001B[0mones\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mones\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 49\u001B[1;33m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcatenate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mones\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     50\u001B[0m         \u001B[0mcost_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mconcatenate\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 14 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "w,cost = gd_model.fit(train,target,0.01,10001)\n",
    "w,cost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}